"use server"
import { NextResponse } from 'next/server';
import OpenAI from 'openai';
import { zodResponseFormat } from 'openai/helpers/zod';
import { z } from 'zod';
import { auth } from '@clerk/nextjs/server';
import { createClient } from "@supabase/supabase-js";
import { MAX_INSTRUCTIONS_LENGTH, MAX_THREAD_CONTEXT_LENGTH } from '../../../lib/constants';
import { ThreadInsightsResponse } from '../../../types';
import { formatUserPromptDescription, getReplyLengthInstructions } from '../../../lib/utils';

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const supabase = createClient(
    process.env.SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_KEY!
);

// Define the response schema using Zod
const ResponseSchema = z.object({
    summary: z.string().describe("A concise summary of the thread context."),
    recommendedAction: z.string().describe("An actionable recommendation based on the thread context."),
    replies: z.array(z.string().describe("An individual AI-generated reply"))
        .describe("A list of replies generated by the AI."),
});

export async function POST(req: Request) {
    try {
        // Check authentication
        const { userId } = await auth();

        if (!userId) {
            return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
        }

        // Get user data and check credits
        const { data: user, error: userError } = await supabase
            .from('users')
            .select('*')
            .eq('clerk_id', userId)
            .single();

        if (userError || !user) {
            return NextResponse.json({ error: "Failed to fetch user data." }, { status: 400 });
        }

        if (user.credits <= 0) {
            return NextResponse.json({ error: "Insufficient credits. Upgrade your plan to continue." }, { status: 403 });
        }

        // Parse request body
        const {
            threadType,
            threadContext,
            instructions,
            tone,
            replyLength,
            customSentences,
            variations,
            useEmojis,
        } = await req.json();

        // Validate required inputs
        if (!threadContext) {
            return NextResponse.json({ error: "Thread context is required." }, { status: 400 });
        }

        if (!threadContext || threadContext.length > MAX_THREAD_CONTEXT_LENGTH) {
            return NextResponse.json(
                { error: `Thread context must not exceed ${MAX_THREAD_CONTEXT_LENGTH} characters.` },
                { status: 400 }
            );
        }

        if (instructions && instructions.length > MAX_INSTRUCTIONS_LENGTH) {
            return NextResponse.json(
                { error: `Instructions must not exceed ${MAX_INSTRUCTIONS_LENGTH} characters.` },
                { status: 400 }
            );
        }

        // Generate the enhanced prompt
        const prompt = `
You are a communication AI specializing in crafting human-like responses for threaded discussions. Follow these instructions to ensure clarity, relevance, and adherence to input parameters:
                ${formatUserPromptDescription(user)}

Input Details:
- Thread Type: ${threadType}. The response should be tailored to this type.
- Thread Context: ${threadContext}
${instructions ? `- Specific Instructions: ${instructions}` : ""}
- Tone: ${tone}
- Reply Length: ${getReplyLengthInstructions(replyLength, customSentences)}
- Number of Replies: ${variations}
${useEmojis ? "- Use emojis where they add value." : "- Avoid using emojis."}

Task:
1. Summarize the thread context in a single concise paragraph.
2. Recommend one clear and actionable next step.
3. Generate ${variations} variations of replies, ensuring they align with the specified tone, length, and style. Use conversational, human-like language while strictly following the input constraints.

Output Format:
{
  "summary": "<Thread Summary>",
  "recommendedAction": "<Recommended Next Step>",
  "replies": ["<Reply 1>", "<Reply 2>", ...]
}`;

        const response = await openai.beta.chat.completions.parse({
            model: "gpt-4o-mini",
            messages: [
                {
                    role: "system",
                    content: `
You must output a JSON object strictly following this schema:
{
  "summary": "string",
  "recommendedAction": "string",
  "replies": ["string", ...]
}
Do not include any extraneous text.`,
                },
                {
                    role: "user",
                    content: prompt,
                },
            ],
            response_format: zodResponseFormat(ResponseSchema, "threadResponse"),
        });

        // Deduct credits
        const { error: updateError } = await supabase
            .from('users')
            .update({ credits: user.credits - 1 })
            .eq('clerk_id', userId);

        if (updateError) {
            console.error("Error updating credits:", updateError);
            return NextResponse.json({ error: "Failed to update credits" }, { status: 500 });
        }

        const result = response.choices[0].message.parsed as ThreadInsightsResponse;
        return NextResponse.json(result);
    } catch (error) {
        console.error("Error generating thread insights:", error);
        return NextResponse.json(
            // @ts-expect-error asdf
            { error: "Failed to generate thread insights.", details: error.message },
            { status: 500 }
        );
    }
}

export async function GET() {
    return NextResponse.json({
        message: "NextJS Starter Thread Insights API",
        supportedParams: [
            "threadType (required)",
            "threadContext (required)",
            "instructions (optional)",
            "tone",
            "replyLength",
            "customSentences (optional)",
            "variations",
            "useEmojis",
        ],
    });
}
